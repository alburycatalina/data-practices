[
  {
    "objectID": "data-practices-for-open-science.html#data-perils-weve-all-dealt-with",
    "href": "data-practices-for-open-science.html#data-perils-weve-all-dealt-with",
    "title": "Data Practices for Open Science",
    "section": "Data Perils We’ve All Dealt With",
    "text": "Data Perils We’ve All Dealt With\n\n\n\n\n\n\nUh-oh!\n\n\n\nWhich version of the dataset was the final one again?\nWho was the last person to edit the pipeline?\nOpening my dataset is slowing my computer down.\nReviewer 2 wants changes. I need to repeat the entire analysis!\n\n\n\n\n\nMany of us have run into these common data perils. These happen because, unlike computers humans have imperfect memories. Keeping perfect track of complex processes like our research can sometimes escape us. That’s why it’s important to set up systems that support us in not ending up in these situations.\nThat’s what we’ll talk about today - open science and the FAIR principles, which encourage us to make our research accessible to others and practical ways to implement these approaches in our research workflows.\nTest"
  },
  {
    "objectID": "data-practices-for-open-science.html#about-me",
    "href": "data-practices-for-open-science.html#about-me",
    "title": "Data Practices for Open Science",
    "section": "About Me",
    "text": "About Me\n\n\n\n\nAlbury C\nMSc, Marine microbial trace nutrient dynamics, Dalhousie University\nCurrently a data scientist for Infrastruture Canada\n\n\n\n\n\n\n\n\n\nThanks for joining me for this presentation.\nI wanted to start by introducing myself before we get into the content.\nMy background is as a microbial ecologist, studying how changing environmental conditions affect marine microbes at the poles.\nI spent a lot of time working with large proetomics and metabolomic datasets for this work, and I began to have a lot of time programming in R and python.\nThat led to me beginning to deliver workshop on scientific programming for youth and other learners.\nI’m currently at data scientist for infrastrure canada, where I’m building tools to better understand how public works projects impact vulnerable communities.\nExcited about open source and data!"
  },
  {
    "objectID": "data-practices-for-open-science.html#about-you",
    "href": "data-practices-for-open-science.html#about-you",
    "title": "Data Practices for Open Science",
    "section": "About You",
    "text": "About You\nVisit the slido here.\n\n\n\nI want to learn a few things about the group before we get started.\nThe best practices that we’ll cover in this presentation will be presented for R, but apply to other open source languages like Python and Julia."
  },
  {
    "objectID": "data-practices-for-open-science.html#open-science",
    "href": "data-practices-for-open-science.html#open-science",
    "title": "Data Practices for Open Science",
    "section": "Open Science",
    "text": "Open Science\n\nAims to make research accessible for the benefits of both scientists and broader society (UNESCO 2023)\nIncreases transparency and the speed of knowledge transfer\n\n\n\nA set of principles and practices that aim to make scientific research from all fields accessible to everyone for the benefits of scientists and society as a whole\nIncreases collaboration and opens processes of scientific knowledge creation.\nExamples of closed science: paywalled journals, supporting data being unavailable or high cost, favoring knowledge produced by high income countries, and hidden or unknown source code or workflow, which is where I’d like to direct attention for talk"
  },
  {
    "objectID": "data-practices-for-open-science.html#fair-principles-1",
    "href": "data-practices-for-open-science.html#fair-principles-1",
    "title": "Data Practices for Open Science",
    "section": "FAIR Principles",
    "text": "FAIR Principles\n\n“Importantly, it is our intent that the principles apply not only to ‘data’ in the conventional sense, but also to the algorithms, tools, and workflows that led to that data.” (Wilkinson et al. 2016)\nFocus on machine actionability\n\n\n\n\nApplies to not just the data itself but also scripts, tools, and workflows\nFocus on machine-actionability. Humans need help from machines because of growing scale and complexity of data"
  },
  {
    "objectID": "data-practices-for-open-science.html#documentation-use-version-control",
    "href": "data-practices-for-open-science.html#documentation-use-version-control",
    "title": "Data Practices for Open Science",
    "section": "Documentation: Use version control",
    "text": "Documentation: Use version control\n\nGit is a popular SCM (source code manager). It can be used through your terminal, browser (ex: Github), or desktop software (ex: GitKraken or your chosen IDE).\nVersion control helps you to avoid circumstances that birth monstrosities like analysis_draft_3_final.R.\nAn example of a Github repository\n\n\n\nGit is a SCM (stands for source code manager)\nVersion control allows for multiple people to contribute to code and also helps you keep track of your project.\nEver seen a file name like this? Piling on information into file name. Git takes care of this."
  },
  {
    "objectID": "data-practices-for-open-science.html#documentation-use-version-control-1",
    "href": "data-practices-for-open-science.html#documentation-use-version-control-1",
    "title": "Data Practices for Open Science",
    "section": "Documentation: Use version control",
    "text": "Documentation: Use version control\n\nIllustration by Allison Horst\n\nGit asks you to create “save points” every time you make a change. Allows you to easily return to previous versions and know what has changed over time.\nIf you’re using excel for analysis, you may notice that it’s difficult to keep track of exactly what has happened.\nWith an OS language like R/Python plus git, you’re unstoppable!"
  },
  {
    "objectID": "data-practices-for-open-science.html#documentation-master-the-art-of-the-readme",
    "href": "data-practices-for-open-science.html#documentation-master-the-art-of-the-readme",
    "title": "Data Practices for Open Science",
    "section": "Documentation: Master the art of the README",
    "text": "Documentation: Master the art of the README\n\nA README acts at the title page of your repository, letting folks who are knew the who, what, where, and why of the analysis.\nUse the README to document anything that might be important if someone brand new was to try to pick up where you’ve left off.\n\n\n\nREADME is landing page. Use it to act as the instruction manual for the code\nComes in very handy when writing methods section of papers"
  },
  {
    "objectID": "data-practices-for-open-science.html#documentation-anticipate-package-conflicts",
    "href": "data-practices-for-open-science.html#documentation-anticipate-package-conflicts",
    "title": "Data Practices for Open Science",
    "section": "Documentation: Anticipate package conflicts",
    "text": "Documentation: Anticipate package conflicts\n\nNote the version of critical packages you used in your analysis. This helps with troubleshooting down the line.\nFor advanced models, some use conda to manage environments and package versions.\n\n\n\nMost of us use packages to add functionality to OS languages\nCan get complicated when versions change over time\nBare minimum is to note the version of critical packages\nConda to manage environments"
  },
  {
    "objectID": "data-practices-for-open-science.html#documentation-anticipate-package-conflicts-1",
    "href": "data-practices-for-open-science.html#documentation-anticipate-package-conflicts-1",
    "title": "Data Practices for Open Science",
    "section": "Documentation: Anticipate package conflicts",
    "text": "Documentation: Anticipate package conflicts\n\n\n\n\n\n\nConflicted?\n\n\nMany of us have had the experience of loading a package that contains a function with the same name as one our code relies on.\nUse the conflicted package to choose which to use.\n\n\n\n\n\nThere may also be conflicts between packages depending on who uses the repo\nThis aside is half about documentation and half coding practice. Documentation because here you’re telling the use which function from which package you mention to use\nThere are many packages with functions named the same thing\nAvoid ambiguity by specifying\n\n\n# Load conflicted package\nlibrary(conflicted)\n\n# Set preference to use only the dplyr filter function \nconflicts_prefer(dplyr::filter())"
  },
  {
    "objectID": "data-practices-for-open-science.html#storing-your-data-use-tidy-data-format",
    "href": "data-practices-for-open-science.html#storing-your-data-use-tidy-data-format",
    "title": "Data Practices for Open Science",
    "section": "Storing Your Data: Use tidy data format",
    "text": "Storing Your Data: Use tidy data format\n\nIllustration from Tidy Data for reproducibility, efficiency, and collaboration by Julia Lowndes and Allison Horst\n\nIn 2014, Hadley Wickam proposed tidy data in a paper in Journal Statistical Software, where every obs is a row and every variable is a column.\nGreat for standardization and machine readability"
  },
  {
    "objectID": "data-practices-for-open-science.html#storing-your-data-redundancy-in-data-is-good",
    "href": "data-practices-for-open-science.html#storing-your-data-redundancy-in-data-is-good",
    "title": "Data Practices for Open Science",
    "section": "Storing Your Data: Redundancy in data is good",
    "text": "Storing Your Data: Redundancy in data is good\n\nUtilize metadata and data dictionaries to link provide important context to your primary data set.\nBefore beginning a project, think about the different ways that data should be stored.\nEx: In a field study, observations from each study site should be kept separate from information about each study site. The two can be linked by unique site identifiers.\n\n\n\nThrough our scientific career, we’re often told to be concise and simplify so this advice may surprise you.\nRedundancy in data is good because it allows you to link between different pieces of information and also saves space.\nAlso plays into tidy data."
  },
  {
    "objectID": "data-practices-for-open-science.html#storing-your-data-redundancy-in-data-is-good-1",
    "href": "data-practices-for-open-science.html#storing-your-data-redundancy-in-data-is-good-1",
    "title": "Data Practices for Open Science",
    "section": "Storing Your Data: Redundancy in data is good",
    "text": "Storing Your Data: Redundancy in data is good\n\nThis table contains two types of observations: song information and Billboard ranking (Wickam 2014)\nOne entry each week the song remains on the Billboard top 100"
  },
  {
    "objectID": "data-practices-for-open-science.html#storing-your-data-redundancy-in-data-is-good-2",
    "href": "data-practices-for-open-science.html#storing-your-data-redundancy-in-data-is-good-2",
    "title": "Data Practices for Open Science",
    "section": "Storing Your Data: Redundancy in data is good",
    "text": "Storing Your Data: Redundancy in data is good\nInstead, they should be saved as:\n\na table with song’s artists, names and run times\na table with details on their Billboard ranking (Wickam 2014).\n\n\n\nJoined by unique identifiers"
  },
  {
    "objectID": "data-practices-for-open-science.html#storing-your-data-redundancy-in-data-is-good-3",
    "href": "data-practices-for-open-science.html#storing-your-data-redundancy-in-data-is-good-3",
    "title": "Data Practices for Open Science",
    "section": "Storing Your Data: Redundancy in data is good",
    "text": "Storing Your Data: Redundancy in data is good\n\nReduces each table to only one type of observation, avoiding confusion\nSaves space\n\n\n\nAvoids confusion. In the first table there are two kinds of temporal data. It could be easy to conflate time and date.\nThe date is actually the date that the song first entered the billboard top 100. The time is the song length.\nSaves space. Say there were 100 songs with an average of 7 entries each. Rather than a table with 700 entries and 7 variables (4900 pieces of data), you now have 2 tables (one with 100 entries and 4 variables and the other with 7 x 100 x 3 = 2100) = 4500."
  },
  {
    "objectID": "data-practices-for-open-science.html#storing-your-data-keep-raw-data-raw",
    "href": "data-practices-for-open-science.html#storing-your-data-keep-raw-data-raw",
    "title": "Data Practices for Open Science",
    "section": "Storing Your Data: Keep raw data raw",
    "text": "Storing Your Data: Keep raw data raw\n\nIn repositories, create a folder named RAW. Place collected data here.\nDo not open these files except to add or remove raw data. Consider setting them to read only when viewing in excel.\nKeep all analysis to your scripts, which will read the data and create outputs from it.\n\n\n\nUse a descriptive file name for any outputs generated from raw data."
  },
  {
    "objectID": "data-practices-for-open-science.html#storing-your-data-manage-your-memory",
    "href": "data-practices-for-open-science.html#storing-your-data-manage-your-memory",
    "title": "Data Practices for Open Science",
    "section": "Storing Your Data: Manage your memory",
    "text": "Storing Your Data: Manage your memory\n\nKeep data types in mind\nConsider parquet for large files\nUse the arrow package to work with larger than memory data sets"
  },
  {
    "objectID": "data-practices-for-open-science.html#storing-your-data-manage-your-memory-1",
    "href": "data-practices-for-open-science.html#storing-your-data-manage-your-memory-1",
    "title": "Data Practices for Open Science",
    "section": "Storing Your Data: Manage your memory",
    "text": "Storing Your Data: Manage your memory\n# Load in large dataset with arrow\nlibrary(arrow)\n\nmassive_dataset <- read.csv(\"massive_dataset.csv\") |> \n  as_arrow_table()"
  },
  {
    "objectID": "data-practices-for-open-science.html#coding-practices-follow-a-style-guide",
    "href": "data-practices-for-open-science.html#coding-practices-follow-a-style-guide",
    "title": "Data Practices for Open Science",
    "section": "Coding Practices: Follow a style guide",
    "text": "Coding Practices: Follow a style guide\nThe Tidyverse Style Guide is a great resource for style guidance.\n# Bad\naverage<-mean(feet/12+inches,na.rm=TRUE)\n\n# Good\naverage <- mean(feet / 12 + inches, na.rm = TRUE)\n\n\nMaking sure your code is legible to others is one of the best ways to make sure it is reusable\nA lot like grammar and style make a language like english easier to read, following style guide helps similarly for code\nStandardized style means others know what to expect\nRelevant for nearly all languages"
  },
  {
    "objectID": "data-practices-for-open-science.html#coding-practices-follow-a-style-guide-1",
    "href": "data-practices-for-open-science.html#coding-practices-follow-a-style-guide-1",
    "title": "Data Practices for Open Science",
    "section": "Coding Practices: Follow a style guide",
    "text": "Coding Practices: Follow a style guide\n\n\n\n\n\n\nAuto-formatting\n\n\nUse cmd + shift + A in R-studio to auto-format your code on the fly.\n\n\n\n\nHandy tip: can highlight and cmd shift A to auto format"
  },
  {
    "objectID": "data-practices-for-open-science.html#coding-practices-more-on-style",
    "href": "data-practices-for-open-science.html#coding-practices-more-on-style",
    "title": "Data Practices for Open Science",
    "section": "Coding Practices: More on Style",
    "text": "Coding Practices: More on Style\nSectioning your code makes it easy for you and others to find the part of the analysis that you’re looking for at a glance.\n\n\n\n\n\n\nAuto-formatting\n\n\nUse cmd + shift + R in Rstudio to create a new collapsible section.\n\n\n\n# separate chunks of code with sections\n\n# new section -------------------------------------------------------------"
  },
  {
    "objectID": "data-practices-for-open-science.html#coding-practices-use-relative-file-paths",
    "href": "data-practices-for-open-science.html#coding-practices-use-relative-file-paths",
    "title": "Data Practices for Open Science",
    "section": "Coding Practices: Use relative file paths",
    "text": "Coding Practices: Use relative file paths\n\nEver tried to run a collaborator’s script only to come up come up with cannot open file 'important-data.csv': No such file or directory? They probably didn’t set the directory for you!\nDon’t instruct your colleague’s computer to look for Desktop/Medical_files/hair-transplant/important-data.csv. Be kind, use a relative file path instead.\n\n\n\nAll of our code should run on the assumption that we are working in a repository that contains of the required files."
  },
  {
    "objectID": "data-practices-for-open-science.html#coding-practices-use-relative-file-paths-1",
    "href": "data-practices-for-open-science.html#coding-practices-use-relative-file-paths-1",
    "title": "Data Practices for Open Science",
    "section": "Coding Practices: Use relative file paths",
    "text": "Coding Practices: Use relative file paths\nRelative paths specify locations starting from the current location.\n# Bad \nlist.files(\"/Users/calbury/Desktop\")\n\n# Better\nlist.files(\"Desktop\")"
  },
  {
    "objectID": "data-practices-for-open-science.html#coding-practices-use-relative-file-paths-2",
    "href": "data-practices-for-open-science.html#coding-practices-use-relative-file-paths-2",
    "title": "Data Practices for Open Science",
    "section": "Coding Practices: Use relative file paths",
    "text": "Coding Practices: Use relative file paths\n\nChange directories throughout the script to access different folders in the repository.\n\n# Relative file path to a dedicated folder with raw data files\nsetwd(\"~/example-repo/RAW\")\nread.csv(\"important-data.csv\")\n\n# Call on another R source file back at the root of the directory \nsetwd(\".\")\nsource(\"analysis.R\")\n\n# Save the results of the analysis in it's own folder\nsetwd(\"/Cleaned_data\")\nwrite.csv(data_output, \"data_output.csv\")"
  },
  {
    "objectID": "data-practices-for-open-science.html#coding-practices-avoid-hard-coded-values",
    "href": "data-practices-for-open-science.html#coding-practices-avoid-hard-coded-values",
    "title": "Data Practices for Open Science",
    "section": "Coding Practices: Avoid hard coded values",
    "text": "Coding Practices: Avoid hard coded values\n\nEver seen code where the logic is impossible to follow due to manual manipulations?\nIf using constants, make sure they’re carefully commented.\nOtherwise, try to utilize variables whenever possible to improve reproducibility"
  },
  {
    "objectID": "data-practices-for-open-science.html#coding-practices-avoid-hard-coded-values-1",
    "href": "data-practices-for-open-science.html#coding-practices-avoid-hard-coded-values-1",
    "title": "Data Practices for Open Science",
    "section": "Coding Practices: Avoid hard coded values",
    "text": "Coding Practices: Avoid hard coded values\n# Bad\nspec_data |> \n  mutate(scatter_normalized = scatter / 2.8)\n  \n# Better \nspec_data |> \n  # Normalize by dividing by constant from calibration\n  mutate(scatter_normalized = scatter / 2.8)\n  \n# Best\n# Load analysis that generates constant\nsource(\"spec_calibration.R\")\n\nspec_data |> \n  # Normalize by dividing by constant from calibration\n  mutate(scatter_normalized = scatter / calibration_value)\n\n\nHow is someone else supposed to know what 2.8 is? Do they keep it as is when they run the script?\nOr maybe it’s just the number of iced coffees the author had today. Impossible to know.\nCalling another script is kind of like citing your sources."
  },
  {
    "objectID": "data-practices-for-open-science.html#conclusions",
    "href": "data-practices-for-open-science.html#conclusions",
    "title": "Data Practices for Open Science",
    "section": "Conclusions",
    "text": "Conclusions\n\nThere are many opportunities to modify your research workflows to both:\n\n\nSave your future self some headache\nMake your science more useful to others\n\n\nA list of resources can be found at the end of the presentation"
  },
  {
    "objectID": "data-practices-for-open-science.html#references",
    "href": "data-practices-for-open-science.html#references",
    "title": "Data Practices for Open Science",
    "section": "References",
    "text": "References\n\nWickham, H. (2014). Tidy Data. Journal of Statistical Software, 59(10), 1–23. https://doi.org/10.18637/jss.v059.i10\nWilkinson, M., Dumontier, M., Aalbersberg, I. et al. The FAIR Guiding Principles for scientific data management and stewardship. Sci Data 3, 160018 (2016). https://doi.org/10.1038/sdata.2016.18\nUNESCO Recommendation on Open Science. 2023"
  },
  {
    "objectID": "data-practices-for-open-science.html#resources",
    "href": "data-practices-for-open-science.html#resources",
    "title": "Data Practices for Open Science",
    "section": "Resources",
    "text": "Resources\n\nSoftware Carpentry: Version Control with Git\nMaking README’s\nTidyverse Style Guide\nConflicted\nLarge Data in R: Tools and Techniques\nData Types in Arrow and R\nWhat is the Parquet File Format? Use Cases & Benefits\nR for Reproducible Research:Navigating Files and Directories\n\n\n\nData Practices for Open Science"
  }
]